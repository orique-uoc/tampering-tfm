{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NOTES**\n",
        "\n",
        "Using this notebook with CASIAv2.0 dataset requires a runtime with at least 4Gb of system RAM and 64GB of disk. With a CPU runtime on Google Colab, it took around 1 hour (or 0.07 compute units) to run the whole notebook."
      ],
      "metadata": {
        "id": "YB6leob2gahw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adT5sjebIAd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddad9086-24b3-49fa-9b31-84e25d498fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_AUTHENTIC_DIRECTORY = '/content/gdrive/MyDrive/TFM/datasets/CASIA2/Au'\n",
        "CNN_TAMPERED_DIRECTORY = '/content/gdrive/MyDrive/TFM/datasets/CASIA2/Tp'\n",
        "CNN_GROUND_TRUTH_DIRECTORY = '/content/gdrive/MyDrive/TFM/datasets/CASIA2/gt_all_grayscale'\n",
        "AUGMENTED_MASK_DIRECTORY = CNN_GROUND_TRUTH_DIRECTORY + \"/augment\""
      ],
      "metadata": {
        "id": "lsNpgl3KINhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMCLWsZjq9kt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "ARRAY_SHAPE = (256, 384) # reshapes down below need to match this (height, width)\n",
        "IMAGE_SIZE = (384, 256)\n",
        "BAND_WIDTH = 10\n",
        "\n",
        "def process_images(directory, is_tampered):\n",
        "    reset_npy_dir(directory)\n",
        "    list_of_files = os.listdir(directory)\n",
        "    print(\"list_of_files\", len(list_of_files), \" \", directory)\n",
        "    for file in list_of_files:\n",
        "      if os.path.isfile(os.path.join(directory, file)):\n",
        "        if not is_tampered or (is_tampered and cnn_groundtruth_exists_dir(file)):\n",
        "          cnn_process_file(directory, file)\n",
        "          augment_image(directory, file, is_tampered)\n",
        "\n",
        "def process_masks(directory):\n",
        "  reset_npy_dir(directory)\n",
        "  generate_authentic_mask_file()\n",
        "  list_of_files = os.listdir(directory)\n",
        "  print(\"list_of_files\", len(list_of_files), \" \", directory)\n",
        "  for file in list_of_files:\n",
        "      if os.path.isfile(os.path.join(directory, file)):\n",
        "          cnn_process_groundtruth(directory, file)\n",
        "\n",
        "def generate_authentic_mask_file():\n",
        "  authentic_mask_filename = get_npy_authentic_file()\n",
        "  array = np.zeros(ARRAY_SHAPE, dtype=np.uint8)\n",
        "  np.save(authentic_mask_filename, array)\n",
        "\n",
        "def get_augmented_image_directory(directory):\n",
        "  return directory + \"/augment\"\n",
        "\n",
        "def augment_image(directory, file, is_tampered):\n",
        "  do_augment = np.random.choice([0, 1], p=[0.47, 0.53]) if is_tampered else np.random.choice([0, 1], p=[0.85, 0.15])\n",
        "  if not do_augment:\n",
        "    return\n",
        "  AUGMENTED_IMAGE_DIRECTORY = get_augmented_image_directory(directory)\n",
        "  if file_exists(get_npy_file(AUGMENTED_IMAGE_DIRECTORY, file)) and file_exists(get_npy_file(AUGMENTED_MASK_DIRECTORY, file)):\n",
        "    return\n",
        "  os.makedirs(AUGMENTED_IMAGE_DIRECTORY + \"/npy\", exist_ok=True)\n",
        "  os.makedirs(AUGMENTED_MASK_DIRECTORY + \"/npy\", exist_ok=True)\n",
        "  gt_image_filename = CNN_GROUND_TRUTH_DIRECTORY + '/' + get_cnn_groundtruth_filename(file)\n",
        "  main_image_filename = directory + '/' + file\n",
        "  for i in range(0, 1): # Apply 1x augmentation\n",
        "    augmented_file = file[:-4] + str(i) + file[-4:]\n",
        "    augment_method_is_rotate = np.random.choice([0, 1], p=[0.5, 0.5])\n",
        "    if augment_method_is_rotate:\n",
        "      augment_with_rotation(main_image_filename, gt_image_filename, directory, augmented_file, is_tampered)\n",
        "    else:\n",
        "      augment_with_flip(main_image_filename, gt_image_filename, directory, augmented_file, is_tampered)\n",
        "\n",
        "def augment_with_flip(main_image_filename, gt_image_filename, directory, augmented_file, is_tampered):\n",
        "  left_right = np.random.choice([0, 1], p=[0.5, 0.5])\n",
        "  if file_exists(get_npy_file(get_augmented_image_directory(directory), augmented_file)):\n",
        "    return\n",
        "  image = cv2.imread(main_image_filename)\n",
        "  image = cv2.resize(image, IMAGE_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
        "  image = cv2.flip(image, 1 if left_right else 0)\n",
        "  array = generate_masked_image_with_contrast_bands(image, BAND_WIDTH)\n",
        "  np.save(get_npy_file(get_augmented_image_directory(directory), augmented_file), array.astype(np.uint8))\n",
        "  if is_tampered:\n",
        "    generate_augmented_flipped_mask(gt_image_filename, left_right, augmented_file)\n",
        "\n",
        "def generate_augmented_flipped_mask(gt_image_filename, left_right, augmented_file):\n",
        "  image = cv2.imread(gt_image_filename)\n",
        "  image = cv2.resize(image, IMAGE_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
        "  image = cv2.flip(image, 1 if left_right else 0)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "  np.save(get_npy_file(AUGMENTED_MASK_DIRECTORY, augmented_file), image.astype(np.uint8))\n",
        "\n",
        "def augment_with_rotation(main_image_filename, gt_image_filename, directory, augmented_file, is_tampered):\n",
        "  angle = random.randint(30, 45) # Between 30ยบ and 45ยบ angle rotation\n",
        "  if file_exists(get_npy_file(get_augmented_image_directory(directory), augmented_file)):\n",
        "    return\n",
        "  image = cv2.imread(main_image_filename)\n",
        "  image = cv2.resize(image, IMAGE_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "  (h, w) = image.shape[:2]\n",
        "  # Specify the center of rotation\n",
        "  center = (w // 2, h // 2)\n",
        "  scale = 1.0  # Scale factor (1.0 means no scaling)\n",
        "  # Get the rotation matrix\n",
        "  rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "  # Perform the rotation\n",
        "  rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
        "\n",
        "  array = generate_masked_image_with_contrast_bands(rotated_image, BAND_WIDTH)\n",
        "\n",
        "  np.save(get_npy_file(get_augmented_image_directory(directory), augmented_file), array.astype(np.uint8))\n",
        "  if is_tampered:\n",
        "    generate_augmented_rotated_mask(gt_image_filename, angle, augmented_file)\n",
        "\n",
        "def generate_augmented_rotated_mask(gt_image_filename, angle, augmented_file):\n",
        "  image = cv2.imread(gt_image_filename)\n",
        "  image = cv2.resize(image, IMAGE_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "\n",
        "  (h, w) = image.shape[:2]\n",
        "  # Specify the center of rotation\n",
        "  center = (w // 2, h // 2)\n",
        "  scale = 1.0  # Scale factor (1.0 means no scaling)\n",
        "  # Get the rotation matrix\n",
        "  rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "  # Perform the rotation\n",
        "  rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
        "  np.save(get_npy_file(AUGMENTED_MASK_DIRECTORY, augmented_file), rotated_image.astype(np.uint8))\n",
        "\n",
        "def reset_npy_dir(directory):\n",
        "    npy_directory = get_npy_directory(directory)\n",
        "    os.makedirs(npy_directory, exist_ok=True)\n",
        "\n",
        "def cnn_process_file(directory, file):\n",
        "    npy_file = get_npy_file(directory, file)\n",
        "    if (os.path.exists(npy_file)):\n",
        "        return\n",
        "    np.save(npy_file, process_image(directory, file))\n",
        "\n",
        "def process_image(directory, file):\n",
        "  image_filename = directory + '/' + file\n",
        "  image = cv2.imread(image_filename)\n",
        "  image = cv2.resize(image, IMAGE_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
        "  array = generate_masked_image_with_contrast_bands(image, BAND_WIDTH)\n",
        "  return array.astype(np.uint8)\n",
        "\n",
        "def cnn_process_groundtruth(directory, file):\n",
        "    npy_file = get_npy_file(directory, file)\n",
        "    if (os.path.exists(npy_file)):\n",
        "        print(\"file, \", npy_file, \"already exists\")\n",
        "        return\n",
        "    np.save(npy_file, process_groundtruth_image(directory, file))\n",
        "\n",
        "def process_groundtruth_image(directory, file):\n",
        "    try:\n",
        "        image_filename = directory + '/' + file\n",
        "        image = Image.open(image_filename, 'r')\n",
        "        image = image.resize(IMAGE_SIZE, Image.LANCZOS)\n",
        "        data = image.getdata()\n",
        "        width, height = image.size\n",
        "        array = np.array(data, dtype=np.uint8).reshape((height, width))\n",
        "        return array\n",
        "    finally:\n",
        "        image.close()\n",
        "\n",
        "def cnn_groundtruth_exists_dir(file):\n",
        "  return os.path.exists(get_cnn_groundtruth_path_dir(file)) # e.g. Tp_S_NNN_S_N_sec00054_sec00055_11341_gt.png does not exist.\n",
        "\n",
        "def get_cnn_groundtruth_path_dir(file):\n",
        "  return CNN_GROUND_TRUTH_DIRECTORY + '/' + get_cnn_groundtruth_filename(file)\n",
        "\n",
        "def get_cnn_groundtruth_filename(file):\n",
        "  return file[:-4] + '_gt.png'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_masked_image_with_contrast_bands(image, extend_radius=3):\n",
        "    # Compute the gradient magnitude\n",
        "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "\n",
        "    # Determine thresholds dynamically\n",
        "    t1 = gradient_magnitude.max() * 0.85\n",
        "    t2 = gradient_magnitude.max() * 0.95\n",
        "    mask = cv2.Canny(image, threshold1=t1, threshold2=t2)\n",
        "\n",
        "    # Extend the mask using dilation (avoiding manual loops)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2 * extend_radius + 1, 2 * extend_radius + 1))\n",
        "    extended_mask = cv2.dilate(mask, kernel)\n",
        "\n",
        "    # Create the extended image\n",
        "    extended_image = np.zeros_like(image)\n",
        "    extended_image[extended_mask > 0] = image[extended_mask > 0]\n",
        "\n",
        "    return extended_image"
      ],
      "metadata": {
        "id": "QYR4OCi6IUW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_npy_directory(directory):\n",
        "    return directory + '/npy'\n",
        "\n",
        "def get_npy_file(directory, file):\n",
        "    return get_npy_directory(directory) + '/' + file + '.npy'\n",
        "\n",
        "def get_npy_authentic_file():\n",
        "    return get_npy_directory(CNN_GROUND_TRUTH_DIRECTORY) + '/authentic.npy'\n",
        "\n",
        "def file_exists(file):\n",
        "  return os.path.exists(file)"
      ],
      "metadata": {
        "id": "TNQzLLYKIU-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process images, find_gradient\n",
        "import concurrent.futures\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Submit both tasks to the executor\n",
        "    future_tampered = executor.submit(process_images, CNN_TAMPERED_DIRECTORY, True)\n",
        "    future_authentic = executor.submit(process_images, CNN_AUTHENTIC_DIRECTORY, False)\n",
        "\n",
        "    # Wait for both tasks to complete and get the results if needed\n",
        "    result_tampered = future_tampered.result()\n",
        "    result_authentic = future_authentic.result()\n",
        "\n",
        "process_masks(CNN_GROUND_TRUTH_DIRECTORY)"
      ],
      "metadata": {
        "id": "Ldmc-AMvIcR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74804e17-aa97-4726-b6c9-f7dcd6a59d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list_of_files 7492   /content/gdrive/MyDrive/TFM/datasets/CASIA2/Au\n",
            "list_of_files 5124   /content/gdrive/MyDrive/TFM/datasets/CASIA2/Tp\n",
            "list_of_files 5125   /content/gdrive/MyDrive/TFM/datasets/CASIA2/gt_all_grayscale\n"
          ]
        }
      ]
    }
  ]
}